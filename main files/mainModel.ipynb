{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    x = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "p1 = MyClass()\n",
    "print(p1.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test:\n",
    "    def __init__(self, num):\n",
    "        self.x = num\n",
    "    def add(self, num):\n",
    "        self.x += num\n",
    "    def sub(self, num):\n",
    "        self.x -= num\n",
    "    def mul(self, num):\n",
    "        self.x *= num\n",
    "    def div(self, num):\n",
    "        self.x /= num\n",
    "    def get(a):\n",
    "        return a.x\n",
    "\n",
    "c = test(5)\n",
    "\n",
    "c.add(2)\n",
    "\n",
    "c.get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class modelManager:\n",
    "    \"\"\"\n",
    "    This is a class to manage the different models, to have the same train test split when using multiple models\n",
    "    Takes the full dataframe, X and target y as input\n",
    "    \"\"\"\n",
    "    def __init__(self, data, X, y) -> None:\n",
    "        self.data = data\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    \"\"\"\n",
    "    This functions will return fitted models with the train test split\n",
    "    \"\"\"\n",
    "    def decisionTree(self) -> dict:\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        model = DecisionTreeClassifier()\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        return {\"model\": model, \"X_train\": self.X_train, \"X_test\": self.X_test, \"y_train\": self.y_train, \"y_test\": self.y_test}\n",
    "    def naiveBayes(self) -> dict:\n",
    "        # make a naive bayes model\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        model = GaussianNB()\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        return {\"model\": model, \"X_train\": self.X_train, \"X_test\": self.X_test, \"y_train\": self.y_train, \"y_test\": self.y_test}\n",
    "    def randomForest(self) -> dict:\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        model = RandomForestClassifier(n_estimators=100)\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        return {\"model\": model, \"X_train\": self.X_train, \"X_test\": self.X_test, \"y_train\": self.y_train, \"y_test\": self.y_test}\n",
    "    def svm(self) -> dict:\n",
    "        from sklearn.svm import SVC\n",
    "        model = SVC(gamma='auto')\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        return {\"model\": model, \"X_train\": self.X_train, \"X_test\": self.X_test, \"y_train\": self.y_train, \"y_test\": self.y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2) (100,)\n"
     ]
    }
   ],
   "source": [
    "# notes\n",
    "\"\"\"\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=100, centers=2, n_features=2, random_state=42)\n",
    "print(X.shape, y.shape)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "# fit model\n",
    "model.fit(X, y)\n",
    "# make predictions\n",
    "yhat = model.predict(X)\n",
    "# evaluate predictions\n",
    "acc = accuracy_score(y, yhat)\n",
    "print(acc)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_blobs\n",
    "# create the inputs and outputs\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=2, random_state=2)\n",
    "# define model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "# fit model\n",
    "model.fit(X, y)\n",
    "# define input\n",
    "new_input = [[2.12309797, -1.41131072]]\n",
    "# get prediction for new input\n",
    "new_output = model.predict(new_input)\n",
    "# summarize input and output\n",
    "print(new_input, new_output)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dea5d8f8cc29cf9e16293dbdf8747b85e5f69ab66d8365066b488317c9976378"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
